{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aa92ecf-d07c-40b1-a45a-0b007251d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('C:/Users/DELL/OneDrive/Documents/data science asignments/EDA2/EDA2/adult_with_headers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43828601-e1ce-42e0-9561-5f6c8fc07c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt    education  education_num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       28            Private  338409    Bachelors             13   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32556   27            Private  257302   Assoc-acdm             12   \n",
       "32557   40            Private  154374      HS-grad              9   \n",
       "32558   58            Private  151910      HS-grad              9   \n",
       "32559   22            Private  201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital_status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital_gain  capital_loss  hours_per_week  native_country  \\\n",
       "0         Male          2174             0              40   United-States   \n",
       "1         Male             0             0              13   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3         Male             0             0              40   United-States   \n",
       "4       Female             0             0              40            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female             0             0              38   United-States   \n",
       "32557     Male             0             0              40   United-States   \n",
       "32558   Female             0             0              40   United-States   \n",
       "32559     Male             0             0              20   United-States   \n",
       "32560   Female         15024             0              40   United-States   \n",
       "\n",
       "       income  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "32556   <=50K  \n",
       "32557    >50K  \n",
       "32558   <=50K  \n",
       "32559   <=50K  \n",
       "32560    >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "017e5c00-aba2-4a4c-bc81-f2de4650f848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                int64\n",
       "workclass         object\n",
       "fnlwgt             int64\n",
       "education         object\n",
       "education_num      int64\n",
       "marital_status    object\n",
       "occupation        object\n",
       "relationship      object\n",
       "race              object\n",
       "sex               object\n",
       "capital_gain       int64\n",
       "capital_loss       int64\n",
       "hours_per_week     int64\n",
       "native_country    object\n",
       "income            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "898f3a31-9f10-4f01-ab78-922b36589fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.581647</td>\n",
       "      <td>1.897784e+05</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>40.437456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.640433</td>\n",
       "      <td>1.055500e+05</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.347429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.178270e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.783560e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.370510e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education_num  capital_gain  capital_loss  \\\n",
       "count  32561.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \n",
       "mean      38.581647  1.897784e+05      10.080679   1077.648844     87.303830   \n",
       "std       13.640433  1.055500e+05       2.572720   7385.292085    402.960219   \n",
       "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours_per_week  \n",
       "count    32561.000000  \n",
       "mean        40.437456  \n",
       "std         12.347429  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f34780-bcce-4c1c-9b9e-6a7b3ac7bf1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education_num     0\n",
       "marital_status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital_gain      0\n",
       "capital_loss      0\n",
       "hours_per_week    0\n",
       "native_country    0\n",
       "income            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4095a6df-13b6-4f5c-92de-17749e1e1a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " age                  0\n",
      "workclass         1836\n",
      "fnlwgt               0\n",
      "education            0\n",
      "education_num        0\n",
      "marital_status       0\n",
      "occupation        1843\n",
      "relationship         0\n",
      "race                 0\n",
      "sex                  0\n",
      "capital_gain         0\n",
      "capital_loss         0\n",
      "hours_per_week       0\n",
      "native_country     583\n",
      "income               0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_17708\\1987929927.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: pd.NA if str(x).strip() == \"?\" else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "file_path = 'C:/Users/DELL/OneDrive/Documents/data science asignments/EDA2/EDA2/adult_with_headers.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove extra spaces and replace \"?\" with NaN across the entire DataFrame\n",
    "df = df.applymap(lambda x: pd.NA if str(x).strip() == \"?\" else x)\n",
    "\n",
    "# Now, check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abaacef5-c019-4548-a5be-a8f405ef1c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "workclass         1836\n",
       "fnlwgt               0\n",
       "education            0\n",
       "education_num        0\n",
       "marital_status       0\n",
       "occupation        1843\n",
       "relationship         0\n",
       "race                 0\n",
       "sex                  0\n",
       "capital_gain         0\n",
       "capital_loss         0\n",
       "hours_per_week       0\n",
       "native_country     583\n",
       "income               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "788c1bfb-e27e-435e-93aa-cc643b7215d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass         0\n",
      "occupation        0\n",
      "native_country    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset and check if it's loaded correctly\n",
    "file_path ='C:/Users/DELL/OneDrive/Documents/data science asignments/EDA2/EDA2/adult_with_headers.csv' \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Replace '?' with NaN\n",
    "df = df.replace('?', pd.NA)\n",
    "\n",
    "# Calculate the mode and fill missing values directly\n",
    "workclass_mode = df['workclass'].mode()[0]\n",
    "df['workclass'] = df['workclass'].fillna(workclass_mode)\n",
    "\n",
    "occupation_mode = df['occupation'].mode()[0]\n",
    "df['occupation'] = df['occupation'].fillna(occupation_mode)\n",
    "\n",
    "native_country_mode = df['native_country'].mode()[0]\n",
    "df['native_country'] = df['native_country'].fillna(native_country_mode)\n",
    "\n",
    "# Confirm no missing values remain in these columns\n",
    "print(df[['workclass', 'occupation', 'native_country']].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d0ed19d-93cd-4b94-a2bc-211530a98bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education_num     0\n",
       "marital_status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital_gain      0\n",
       "capital_loss      0\n",
       "hours_per_week    0\n",
       "native_country    0\n",
       "income            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca834261-db35-4159-ae4b-ec969b00ef1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset saved to: C:/Users/DELL/OneDrive/Documents/data science asignments/EDA2/EDA2/adultt_processed.csv\n"
     ]
    }
   ],
   "source": [
    "processed_file_path = 'C:/Users/DELL/OneDrive/Documents/data science asignments/EDA2/EDA2/adultt_processed.csv'\n",
    "df.to_csv(processed_file_path, index=False)\n",
    "\n",
    "print(f\"Processed dataset saved to: {processed_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52308deb-9c83-44ad-aaef-1cd03fc006b5",
   "metadata": {},
   "source": [
    "Standard Scaling\n",
    "Standard scaling (Z-score normalization) transforms the data to have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fdccf73-e53e-489e-8a21-d26034552715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Scaled Data:\n",
      "        age    fnlwgt  education_num  capital_gain  capital_loss  \\\n",
      "0  0.030671 -1.063611       1.134739      0.148453      -0.21666   \n",
      "1  0.837109 -1.008707       1.134739     -0.145920      -0.21666   \n",
      "2 -0.042642  0.245079      -0.420060     -0.145920      -0.21666   \n",
      "3  1.057047  0.425801      -1.197459     -0.145920      -0.21666   \n",
      "4 -0.775768  1.408176       1.134739     -0.145920      -0.21666   \n",
      "\n",
      "   hours_per_week  \n",
      "0       -0.035429  \n",
      "1       -2.222153  \n",
      "2       -0.035429  \n",
      "3       -0.035429  \n",
      "4       -0.035429  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select numerical features\n",
    "numerical_features = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply standard scaling\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "print(\"Standard Scaled Data:\")\n",
    "print(df[numerical_features].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db786278-8c13-4310-84a1-5c2b52be1db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Min-Max Scaling\n",
    "Min-Max scaling transforms the data to a fixed range, usually [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b9566b4-f182-4c13-8049-6ea6b22d2aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min-Max Scaled Data:\n",
      "        age    fnlwgt  education_num  capital_gain  capital_loss  \\\n",
      "0  0.301370  0.044302       0.800000       0.02174           0.0   \n",
      "1  0.452055  0.048238       0.800000       0.00000           0.0   \n",
      "2  0.287671  0.138113       0.533333       0.00000           0.0   \n",
      "3  0.493151  0.151068       0.400000       0.00000           0.0   \n",
      "4  0.150685  0.221488       0.800000       0.00000           0.0   \n",
      "\n",
      "   hours_per_week  \n",
      "0        0.397959  \n",
      "1        0.122449  \n",
      "2        0.397959  \n",
      "3        0.397959  \n",
      "4        0.397959  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Apply min-max scaling\n",
    "df[numerical_features] = min_max_scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "print(\"Min-Max Scaled Data:\")\n",
    "print(df[numerical_features].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e9f413-287f-40f9-ba7f-27bd81395a30",
   "metadata": {},
   "source": [
    "Analyzing the outputs of both Standard Scaling and Min-Max Scaling can provide insights into how these techniques transform the data and their implications for subsequent analysis or modeling. Hereâ€™s a detailed analysis based on the provided scaled data:\n",
    "Overview of Scaled Data\n",
    "Standard Scaled Data:\n",
    "The values are centered around 0 with a standard deviation of 1.\n",
    "This scaling method is particularly useful when the features are normally distributed or when using algorithms sensitive to the scale of input data.\n",
    "Min-Max Scaled Data:\n",
    "The values are transformed to a range between 0 and 1.\n",
    "This approach is beneficial when you want to ensure that all features contribute equally to distance calculations, particularly in algorithms like K-nearest neighbors (KNN) or neural networks.\n",
    "Analysis of Both Scaling Techniques\n",
    "1. Standard Scaling Analysis\n",
    "Data Distribution:\n",
    "The output shows that after standard scaling, values can be both positive and negative. For instance, an age value of 0.030671 indicates it is slightly above the mean, while -0.775768 suggests it is below average.\n",
    "Implications:\n",
    "Models that assume normally distributed data (like linear regression or logistic regression) can benefit from this scaling because it maintains the relationships between features while normalizing their distributions.\n",
    "Outlier Influence:\n",
    "While standard scaling does not eliminate outliers, it reduces their influence compared to Min-Max scaling, which can compress the range of non-outlier values.\n",
    "2. Min-Max Scaling Analysis\n",
    "Range Transformation:\n",
    "All values are confined within the range of [0, 1]. For example, an age value of 0.301370 indicates that this individual falls within a certain percentile of the dataset.\n",
    "Implications:\n",
    "This scaling technique is particularly useful for algorithms that require bounded input, such as neural networks with activation functions like sigmoid or tanh.\n",
    "Sensitivity to Outliers:\n",
    "Min-Max scaling is sensitive to outliers because it uses the minimum and maximum values for scaling. If there are extreme values in the dataset, they can significantly distort the scaled values of other observations.\n",
    "Comparison of Outputs\n",
    "Feature\tStandard Scaled Value\tMin-Max Scaled Value\n",
    "Age\t0.030671\t0.301370\n",
    "Fnlwgt\t-1.063611\t0.044302\n",
    "Education_num\t1.134739\t0.800000\n",
    "Capital_gain\t0.148453\t0.021740\n",
    "Capital_loss\t-0.216660\t0.000000\n",
    "Hours_per_week\t-0.035429\t0.397959\n",
    "Key Takeaways\n",
    "Model Selection: Choose Standard Scaling when using models that assume normality in the data distribution or when dealing with algorithms sensitive to feature magnitudes (e.g., SVM, PCA). Opt for Min-Max Scaling when working with algorithms that require bounded inputs or when you need to preserve relationships between features.\n",
    "Feature Interpretation: After applying standard scaling, you can interpret how far each observation deviates from the mean, which can be useful in understanding feature importance and relationships in models.\n",
    "Impact on Distance Metrics: In distance-based algorithms (like KNN), Min-Max Scaling ensures that all features contribute equally since they are on the same scale, preventing features with larger ranges from dominating distance calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c044fd20-35a6-445c-aad8-e873d06c011c",
   "metadata": {},
   "source": [
    "One-Hot Encoding and Label Encoding are two common techniques used to convert categorical variables into a numerical format that can be used in machine learning algorithms. Here's a detailed explanation of each method and how they function:\n",
    "One-Hot Encoding\n",
    "Definition: One-Hot Encoding transforms categorical variables into a format that can be provided to machine learning algorithms to improve predictions. It creates binary (0 or 1) columns for each category in the original variable.\n",
    "How It Works:\n",
    "For each unique category in the categorical variable, a new binary column is created.\n",
    "Each observation is marked with a 1 in the column corresponding to its category and 0 in all other new columns.\n",
    "Example:\n",
    "Suppose you have a categorical variable Color with three categories: Red, Green, and Blue.\n",
    "Color\n",
    "Red\n",
    "Green\n",
    "Blue\n",
    "Green\n",
    "Red\n",
    "Using One-Hot Encoding, this would be transformed into:\n",
    "Color_Red\tColor_Green\tColor_Blue\n",
    "1\t0\t0\n",
    "0\t1\t0\n",
    "0\t0\t1\n",
    "0\t1\t0\n",
    "1\t0\t0\n",
    "Label Encoding\n",
    "Definition: Label Encoding converts categorical variables into numerical values by assigning each unique category an integer value. This method is straightforward but can introduce unintended ordinal relationships between categories.\n",
    "How It Works:\n",
    "Each unique category is assigned a unique integer starting from 0.\n",
    "The original categorical variable is replaced with these integer values.\n",
    "Example:\n",
    "Using the same Color variable:\n",
    "Color\n",
    "Red\n",
    "Green\n",
    "Blue\n",
    "Green\n",
    "Red\n",
    "Using Label Encoding, this would be transformed into:\n",
    "Color (Encoded)\n",
    "2\n",
    "1\n",
    "0\n",
    "1\n",
    "2\n",
    "Key Differences\n",
    "Output Format:\n",
    "One-Hot Encoding results in multiple binary columns for each category.\n",
    "Label Encoding results in a single column with integer values.\n",
    "Interpretation of Values:\n",
    "In One-Hot Encoding, there is no ordinal relationship implied; each category is independent.\n",
    "In Label Encoding, the integer values imply an order, which may not exist between categories.\n",
    "When to Use Each Method\n",
    "One-Hot Encoding is preferred when:\n",
    "The categorical variable does not have an ordinal relationship.\n",
    "The number of unique categories is relatively small (to avoid high dimensionality).\n",
    "Label Encoding is preferred when:\n",
    "The categorical variable has an ordinal relationship (e.g., ratings like \"low,\" \"medium,\" \"high\").\n",
    "The number of unique categories is large, and creating many binary columns would lead to excessive dimensionality.\n",
    "Conclusion\n",
    "Both One-Hot Encoding and Label Encoding are essential techniques for preparing categorical data for machine learning. The choice between them depends on the nature of the data and the specific requirements of the algorithms being used. Understanding how they work helps ensure that your models are trained effectively without introducing bias or misinterpretation of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "357b12d3-f6f8-4220-95dc-bbe6e4fa945e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age  workclass    fnlwgt  education  education_num  marital_status  \\\n",
      "0  0.301370        5.0  0.044302        9.0       0.800000             4.0   \n",
      "1  0.452055        4.0  0.048238        9.0       0.800000             2.0   \n",
      "2  0.287671        2.0  0.138113       11.0       0.533333             0.0   \n",
      "3  0.493151        2.0  0.151068        1.0       0.400000             2.0   \n",
      "4  0.150685        2.0  0.221488        9.0       0.800000             2.0   \n",
      "\n",
      "   occupation  capital_gain  capital_loss  hours_per_week  ...  \\\n",
      "0         0.0       0.02174           0.0        0.397959  ...   \n",
      "1         3.0       0.00000           0.0        0.122449  ...   \n",
      "2         5.0       0.00000           0.0        0.397959  ...   \n",
      "3         5.0       0.00000           0.0        0.397959  ...   \n",
      "4         9.0       0.00000           0.0        0.397959  ...   \n",
      "\n",
      "   race_Asian-Pac-Islander race_Black  race_Other  race_White  \\\n",
      "0                      0.0        0.0         0.0         1.0   \n",
      "1                      0.0        0.0         0.0         1.0   \n",
      "2                      0.0        0.0         0.0         1.0   \n",
      "3                      0.0        1.0         0.0         0.0   \n",
      "4                      0.0        1.0         0.0         0.0   \n",
      "\n",
      "   relationship_Husband  relationship_Not-in-family  \\\n",
      "0                   0.0                         1.0   \n",
      "1                   1.0                         0.0   \n",
      "2                   0.0                         1.0   \n",
      "3                   1.0                         0.0   \n",
      "4                   0.0                         0.0   \n",
      "\n",
      "   relationship_Other-relative  relationship_Own-child  \\\n",
      "0                          0.0                     0.0   \n",
      "1                          0.0                     0.0   \n",
      "2                          0.0                     0.0   \n",
      "3                          0.0                     0.0   \n",
      "4                          0.0                     0.0   \n",
      "\n",
      "   relationship_Unmarried  relationship_Wife  \n",
      "0                     0.0                0.0  \n",
      "1                     0.0                0.0  \n",
      "2                     0.0                0.0  \n",
      "3                     0.0                0.0  \n",
      "4                     0.0                1.0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "\n",
    "# Replace '?' with NaN for proper handling of missing values\n",
    "df.replace('?', pd.NA, inplace=True)\n",
    "\n",
    "# Drop rows with missing values (or handle them as needed)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Initialize encoders\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)  # Updated parameter name\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply One-Hot Encoding to categorical variables with < 5 categories\n",
    "one_hot_columns = ['sex', 'race', 'relationship']\n",
    "one_hot_encoded = one_hot_encoder.fit_transform(df[one_hot_columns])\n",
    "one_hot_df = pd.DataFrame(one_hot_encoded, columns=one_hot_encoder.get_feature_names_out(one_hot_columns))\n",
    "\n",
    "# Apply Label Encoding to categorical variables with > 5 categories\n",
    "label_columns = ['workclass', 'education', 'marital_status', 'occupation', 'native_country']\n",
    "for col in label_columns:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Combine the original DataFrame with the one-hot encoded DataFrame\n",
    "df_encoded = pd.concat([df.drop(one_hot_columns, axis=1), one_hot_df], axis=1)\n",
    "\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f000cb5-dbb8-49f5-a136-40b0fcb83f06",
   "metadata": {},
   "source": [
    ". Feature Engineering:\n",
    "â€¢\tCreate at least 2 new features that could be beneficial for the model. Explain the rationale behind your choices.\n",
    "â€¢\tApply a transformation (e.g., log transformation) to at least one skewed numerical feature and justify your choice.\n",
    "To enhance the dataset through feature engineering, we will create two new features and apply a transformation to one skewed numerical feature. Below are the details of the new features and the rationale behind their creation, as well as the transformation applied to a numerical feature.\r\n",
    "New Features Creation\r\n",
    "1. Income Binary Feature\r\n",
    "Feature Name: income_binary\r\n",
    "Description: This feature will convert the income categorical variable into a binary format (0 for <=50K and 1 for >50K).\r\n",
    "Rationale: Many machine learning algorithms perform better with numerical inputs. By converting income into a binary format, we can simplify the model's task of predicting income levels based on other features.\r\n",
    "2. Experience Level\r\n",
    "Feature Name: experience_level\r\n",
    "Description: This feature will be derived from the education_num and age columns to estimate an individualâ€™s experience level. It can be calculated as:\r\n",
    "experience level\r\n",
    "=\r\n",
    "age\r\n",
    "âˆ’\r\n",
    "education num\r\n",
    "âˆ’\r\n",
    "6\r\n",
    "experience level=ageâˆ’education numâˆ’6\r\n",
    "Here, we subtract 6 years, assuming that formal education typically starts at age 6.\r\n",
    "Rationale: This feature could provide insights into how age and education interact to influence income potential. A higher experience level may correlate with higher income.\r\n",
    "Applying Transformations\r\n",
    "Log Transformation on fnlwgt\r\n",
    "Feature Name: fnlwgt\r\n",
    "Transformation: Apply a log transformation.\r\n",
    "Rationale: The fnlwgt (final weight) feature is often skewed, meaning it has a long tail of high values. Log transformation helps in normalizing this skewness, making it more suitable for linear models that assume normally distributed data. It can also stabilize variance and make the data more interpretable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4c2e7c3-f996-4fcc-b5c8-22ced4e5372c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   income_binary  experience_level  fnlwgt_log\n",
      "0              0         -6.498630   -3.116728\n",
      "1              0         -6.347945   -3.031617\n",
      "2              0         -6.245662   -1.979680\n",
      "3              0         -5.906849   -1.890023\n",
      "4              0         -6.649315   -1.507385\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "\n",
    "# Replace '?' with NaN for proper handling of missing values\n",
    "df.replace('?', pd.NA, inplace=True)\n",
    "\n",
    "# Drop rows with missing values (or handle them as needed)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Create binary income feature\n",
    "df['income_binary'] = df['income'].apply(lambda x: 1 if x == '>50K' else 0)\n",
    "\n",
    "# Create experience level feature\n",
    "df['experience_level'] = df['age'] - df['education_num'] - 6\n",
    "\n",
    "# Apply log transformation to fnlwgt\n",
    "df['fnlwgt_log'] = np.log(df['fnlwgt'])\n",
    "\n",
    "# Display the updated DataFrame with new features\n",
    "print(df[['income_binary', 'experience_level', 'fnlwgt_log']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5f28f7-2bfb-4937-817a-d76366899cac",
   "metadata": {},
   "source": [
    "By creating the income_binary and experience_level features, we enhance the dataset's potential for predictive modeling. The log transformation applied to fnlwgt addresses skewness, making it more suitable for analysis. These modifications aim to improve model performance and interpretability by providing additional insights into relationships within the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11b9712-c305-465c-b024-35bf440fd8c8",
   "metadata": {},
   "source": [
    "Feature Selection: Outlier Detection and Predictive Power Score\n",
    "In this section, we will use the Isolation Forest algorithm to identify and remove outliers from the dataset, followed by applying the Predictive Power Score (PPS) to analyze relationships between features. We will also compare the findings from PPS with those from a correlation matrix.\n",
    "1. Outlier Detection Using Isolation Forest\n",
    "Isolation Forest is an effective algorithm for detecting outliers in high-dimensional datasets. It works by isolating observations through random partitioning, where outliers are easier to isolate compared to normal observations.\n",
    "Implementation of Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "826f1d4f-8530-4446-a995-7da53f57997c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 30162\n",
      "Cleaned dataset size: 28653\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "\n",
    "# Replace '?' with NaN for proper handling of missing values\n",
    "df.replace('?', pd.NA, inplace=True)\n",
    "\n",
    "# Drop rows with missing values (or handle them as needed)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Select numerical features for outlier detection\n",
    "numerical_features = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "\n",
    "# Initialize Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.05)  # Assuming 5% of data may be outliers\n",
    "\n",
    "# Fit the model and predict outliers\n",
    "outlier_predictions = iso_forest.fit_predict(df[numerical_features])\n",
    "\n",
    "# Add predictions to DataFrame: -1 for outliers, 1 for inliers\n",
    "df['outlier'] = outlier_predictions\n",
    "\n",
    "# Remove outliers from the dataset\n",
    "df_cleaned = df[df['outlier'] != -1]\n",
    "\n",
    "print(f\"Original dataset size: {df.shape[0]}\")\n",
    "print(f\"Cleaned dataset size: {df_cleaned.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4026541c-d116-446b-bb69-790fa9994372",
   "metadata": {},
   "source": [
    "Discussion: How Outliers Affect Model Performance\n",
    "Bias in Predictions: Outliers can skew the results of statistical models, leading to biased estimates and predictions. For example, linear regression can be heavily influenced by extreme values, resulting in a model that does not generalize well to new data.\n",
    "Increased Variance: Models may become overly complex if they try to fit to outliers, leading to overfitting. This reduces the model's ability to perform well on unseen data.\n",
    "Impact on Metrics: Outliers can distort performance metrics such as mean squared error (MSE), making it difficult to assess model performance accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beebcb9-a0f9-4c68-b0da-c905cf15b8c4",
   "metadata": {},
   "source": [
    ". Predictive Power Score (PPS)\n",
    "The Predictive Power Score (PPS) quantifies the predictive power of one feature over another, providing insights into their relationships. It ranges from 0 (no predictive power) to 1 (perfect predictive power).\n",
    "Implementation of PPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2bcce0f-4092-4024-a69c-a1279382cd80",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ppscore'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mppscore\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpps\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Calculate PPS for all feature pairs\u001b[39;00m\n\u001b[0;32m      4\u001b[0m pps_matrix \u001b[38;5;241m=\u001b[39m pps\u001b[38;5;241m.\u001b[39mmatrix(df_cleaned)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ppscore'"
     ]
    }
   ],
   "source": [
    "import ppscore as pps\n",
    "\n",
    "# Calculate PPS for all feature pairs\n",
    "pps_matrix = pps.matrix(df_cleaned)\n",
    "\n",
    "# Display the PPS matrix\n",
    "print(pps_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f37702ae-1e47-462a-a2fc-a50341890d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     age    fnlwgt  education_num  capital_gain  capital_loss  \\\n",
      "age             1.000000 -0.082777       0.044908      0.088587      0.034414   \n",
      "fnlwgt         -0.082777  1.000000      -0.041352     -0.016057     -0.016374   \n",
      "education_num   0.044908 -0.041352       1.000000      0.138579      0.029878   \n",
      "capital_gain    0.088587 -0.016057       0.138579      1.000000     -0.031959   \n",
      "capital_loss    0.034414 -0.016374       0.029878     -0.031959      1.000000   \n",
      "hours_per_week  0.119033 -0.020885       0.136192      0.073250      0.022205   \n",
      "\n",
      "                hours_per_week  \n",
      "age                   0.119033  \n",
      "fnlwgt               -0.020885  \n",
      "education_num         0.136192  \n",
      "capital_gain          0.073250  \n",
      "capital_loss          0.022205  \n",
      "hours_per_week        1.000000  \n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = df_cleaned[numerical_features].corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7f4b19-dc1b-47fe-91d2-3a759d6e8414",
   "metadata": {},
   "source": [
    "Discussion: Comparing PPS and Correlation Matrix Findings\n",
    "Nature of Relationships:\n",
    "Correlation Matrix: Only captures linear relationships. For example, a high positive correlation between age and education_num indicates that older individuals tend to have higher education levels.\n",
    "PPS: Captures both linear and non-linear relationships. It can reveal complex interactions that might not be evident in the correlation matrix.\n",
    "Interpretation:\n",
    "The correlation matrix might show a strong relationship between two features, but PPS could indicate that one feature has little predictive power over another when considering other variables.\n",
    "Outlier Influence:\n",
    "The correlation matrix can be significantly influenced by outliers, while PPS provides a more robust measure of predictive power that is less affected by extreme values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
