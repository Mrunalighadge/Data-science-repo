{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67d458ea-8b62-4279-ab52-0ec5347bb2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
       "0      T     2     8      3       5      1     8    13      0      6      6   \n",
       "1      I     5    12      3       7      2    10     5      5      4     13   \n",
       "2      D     4    11      6       8      6    10     6      2      6     10   \n",
       "3      N     7    11      6       6      3     5     9      4      6      4   \n",
       "4      G     2     1      3       1      1     8     6      6      6      6   \n",
       "\n",
       "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0      10       8      0       8      0       8  \n",
       "1       3       9      2       8      4      10  \n",
       "2       3       7      3       7      3       9  \n",
       "3       4      10      6      10      2       8  \n",
       "4       5       9      1       7      5      10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of dataset:\n",
      " {'Number of samples': 20000, 'Number of features': 16, 'Classes': 16, 'Class Distribution': yedgex\n",
      "8     8047\n",
      "7     3472\n",
      "9     2358\n",
      "6     1827\n",
      "10    1578\n",
      "5      992\n",
      "11     868\n",
      "4      478\n",
      "12     137\n",
      "3      130\n",
      "13      49\n",
      "2       30\n",
      "1       17\n",
      "14      13\n",
      "15       2\n",
      "0        2\n",
      "Name: count, dtype: int64}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:/Users/DELL/OneDrive/Documents/data science asignments/Neural networks/Neural networks/Alphabets_data.csv'  # Update this path if needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Summarize key features of the dataset\n",
    "summary = {\n",
    "    \"Number of samples\": data.shape[0],\n",
    "    \"Number of features\": data.shape[1] - 1,  # Assuming the last column is the target class\n",
    "    \"Classes\": data.iloc[:, -1].nunique(),  # Assuming the last column is the target class\n",
    "    \"Class Distribution\": data.iloc[:, -1].value_counts()\n",
    "}\n",
    "\n",
    "# Display first few rows and summary\n",
    "display(data.head())\n",
    "print(\"Summary of dataset:\\n\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c8b182a-eb3b-4cd1-a975-8a208baa3379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
       "0      T     2     8      3       5      1     8    13      0      6      6   \n",
       "1      I     5    12      3       7      2    10     5      5      4     13   \n",
       "2      D     4    11      6       8      6    10     6      2      6     10   \n",
       "3      N     7    11      6       6      3     5     9      4      6      4   \n",
       "4      G     2     1      3       1      1     8     6      6      6      6   \n",
       "\n",
       "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0      10       8      0       8      0       8  \n",
       "1       3       9      2       8      4      10  \n",
       "2       3       7      3       7      3       9  \n",
       "3       4      10      6      10      2       8  \n",
       "4       5       9      1       7      5      10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of dataset:\n",
      "{'Number of samples': 20000, 'Number of features': 16, 'Classes': 16, 'Class Distribution': yedgex\n",
      "8     8047\n",
      "7     3472\n",
      "9     2358\n",
      "6     1827\n",
      "10    1578\n",
      "5      992\n",
      "11     868\n",
      "4      478\n",
      "12     137\n",
      "3      130\n",
      "13      49\n",
      "2       30\n",
      "1       17\n",
      "14      13\n",
      "15       2\n",
      "0        2\n",
      "Name: count, dtype: int64}\n",
      "\n",
      "Missing values in each column:\n",
      "letter    0\n",
      "xbox      0\n",
      "ybox      0\n",
      "width     0\n",
      "height    0\n",
      "onpix     0\n",
      "xbar      0\n",
      "ybar      0\n",
      "x2bar     0\n",
      "y2bar     0\n",
      "xybar     0\n",
      "x2ybar    0\n",
      "xy2bar    0\n",
      "xedge     0\n",
      "xedgey    0\n",
      "yedge     0\n",
      "yedgex    0\n",
      "dtype: int64\n",
      "\n",
      "Data shape after cleaning missing values: (20000, 17)\n",
      "\n",
      "Summary after preprocessing:\n",
      "{'Missing Values After Cleaning': 0, 'Data Shape After Cleaning': (20000, 17), 'Data Shape After Normalization': (20000, 17), 'Feature Range After Normalization': (0.0, 1.0)}\n",
      "\n",
      "First few rows of the normalized dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "      <th>letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       xbox      ybox  width    height     onpix      xbar      ybar  \\\n",
       "0  0.133333  0.533333    0.2  0.333333  0.066667  0.533333  0.866667   \n",
       "1  0.333333  0.800000    0.2  0.466667  0.133333  0.666667  0.333333   \n",
       "2  0.266667  0.733333    0.4  0.533333  0.400000  0.666667  0.400000   \n",
       "3  0.466667  0.733333    0.4  0.400000  0.200000  0.333333  0.600000   \n",
       "4  0.133333  0.066667    0.2  0.066667  0.066667  0.533333  0.400000   \n",
       "\n",
       "      x2bar     y2bar     xybar    x2ybar    xy2bar     xedge    xedgey  \\\n",
       "0  0.000000  0.400000  0.400000  0.666667  0.533333  0.000000  0.533333   \n",
       "1  0.333333  0.266667  0.866667  0.200000  0.600000  0.133333  0.533333   \n",
       "2  0.133333  0.400000  0.666667  0.200000  0.466667  0.200000  0.466667   \n",
       "3  0.266667  0.400000  0.266667  0.266667  0.666667  0.400000  0.666667   \n",
       "4  0.400000  0.400000  0.400000  0.333333  0.600000  0.066667  0.466667   \n",
       "\n",
       "      yedge    yedgex letter  \n",
       "0  0.000000  0.533333      T  \n",
       "1  0.266667  0.666667      I  \n",
       "2  0.200000  0.600000      D  \n",
       "3  0.133333  0.533333      N  \n",
       "4  0.333333  0.666667      G  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initial exploration: Display first few rows and summary\n",
    "print(\"First few rows of the dataset:\")\n",
    "display(data.head())\n",
    "\n",
    "summary = {\n",
    "    \"Number of samples\": data.shape[0],\n",
    "    \"Number of features\": data.shape[1] - 1,  # Assuming last column is the target class\n",
    "    \"Classes\": data.iloc[:, -1].nunique(),    # Assuming last column is the target class\n",
    "    \"Class Distribution\": data.iloc[:, -1].value_counts()\n",
    "}\n",
    "print(\"\\nSummary of dataset:\")\n",
    "print(summary)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Drop rows with missing values (if any) as a first approach\n",
    "data_cleaned = data.dropna()\n",
    "print(\"\\nData shape after cleaning missing values:\", data_cleaned.shape)\n",
    "\n",
    "# Initialize the MinMaxScaler for normalization\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize features (assuming 'letter' is the target column, adjust if needed)\n",
    "features = data_cleaned.drop(columns=['letter'])\n",
    "normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "# Create a new DataFrame with normalized features and the target column\n",
    "data_normalized = pd.DataFrame(normalized_features, columns=features.columns)\n",
    "data_normalized['letter'] = data_cleaned['letter'].values\n",
    "\n",
    "# Summary after preprocessing\n",
    "data_normalized_summary = {\n",
    "    \"Missing Values After Cleaning\": data_cleaned.isnull().sum().sum(),\n",
    "    \"Data Shape After Cleaning\": data_cleaned.shape,\n",
    "    \"Data Shape After Normalization\": data_normalized.shape,\n",
    "    \"Feature Range After Normalization\": (data_normalized.drop(columns=['letter']).min().min(), \n",
    "                                          data_normalized.drop(columns=['letter']).max().max())\n",
    "}\n",
    "print(\"\\nSummary after preprocessing:\")\n",
    "print(data_normalized_summary)\n",
    "\n",
    "# Display first few rows of the normalized data\n",
    "print(\"\\nFirst few rows of the normalized dataset:\")\n",
    "display(data_normalized.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe6e025-5dea-4b6f-b190-68b5006334ed",
   "metadata": {},
   "source": [
    "2. Model Implementation\n",
    "●\tConstruct a basic ANN model using your chosen high-level neural network library. Ensure your model includes at least one hidden layer.\n",
    "●\tDivide the dataset into training and test sets.\n",
    "●\tTrain your model on the training set and then use it to make predictions on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fa2c9c6-6ed1-4b4f-8e8c-8b20552a3d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">858</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m1,088\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)                  │             \u001b[38;5;34m858\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,026</span> (15.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,026\u001b[0m (15.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,026</span> (15.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,026\u001b[0m (15.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1294 - loss: 3.1155 - val_accuracy: 0.4094 - val_loss: 2.1931\n",
      "Epoch 2/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4737 - loss: 1.9548 - val_accuracy: 0.5566 - val_loss: 1.6020\n",
      "Epoch 3/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5685 - loss: 1.5125 - val_accuracy: 0.6072 - val_loss: 1.4169\n",
      "Epoch 4/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6069 - loss: 1.3551 - val_accuracy: 0.6306 - val_loss: 1.3180\n",
      "Epoch 5/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6400 - loss: 1.2415 - val_accuracy: 0.6488 - val_loss: 1.2426\n",
      "Epoch 6/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6600 - loss: 1.1892 - val_accuracy: 0.6800 - val_loss: 1.1844\n",
      "Epoch 7/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6760 - loss: 1.1202 - val_accuracy: 0.6897 - val_loss: 1.1450\n",
      "Epoch 8/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6965 - loss: 1.0913 - val_accuracy: 0.7059 - val_loss: 1.0883\n",
      "Epoch 9/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7097 - loss: 1.0402 - val_accuracy: 0.7134 - val_loss: 1.0559\n",
      "Epoch 10/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7176 - loss: 1.0402 - val_accuracy: 0.7219 - val_loss: 1.0456\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7290 - loss: 0.9937\n",
      "Test Loss: 1.007820725440979\n",
      "Test Accuracy: 0.7307500243186951\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = data_normalized.drop(columns=['letter'])\n",
    "y = pd.get_dummies(data_normalized['letter'])  # One-hot encode the target classes\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the ANN model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # Hidden layer with 64 neurons\n",
    "    Dense(32, activation='relu'),                                  # Additional hidden layer (optional)\n",
    "    Dense(y.shape[1], activation='softmax')                        # Output layer with softmax for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180a6ce9-1ac1-4d75-9035-7f395e4409c0",
   "metadata": {},
   "source": [
    "●\tDivide the dataset into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "749bc744-cd38-4b46-b94c-292db2673082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape (X_train, y_train): (16000, 16) (16000, 26)\n",
      "Test Set Shape (X_test, y_test): (4000, 16) (4000, 26)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = data_normalized.drop(columns=['letter'])\n",
    "y = pd.get_dummies(data_normalized['letter'])  # One-hot encode the target classes\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Summary of the split\n",
    "print(\"Training Set Shape (X_train, y_train):\", X_train.shape, y_train.shape)\n",
    "print(\"Test Set Shape (X_test, y_test):\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f914f7b-a88c-408b-929a-68b8081fa03a",
   "metadata": {},
   "source": [
    "●\tTrain your model on the training set and then use it to make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "691ffaaa-2edc-4616-92af-971247f249b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7252 - loss: 1.0147 - val_accuracy: 0.7244 - val_loss: 1.0163\n",
      "Epoch 2/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7451 - loss: 0.9723 - val_accuracy: 0.7369 - val_loss: 0.9926\n",
      "Epoch 3/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7467 - loss: 0.9481 - val_accuracy: 0.7337 - val_loss: 0.9815\n",
      "Epoch 4/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7533 - loss: 0.9068 - val_accuracy: 0.7491 - val_loss: 0.9343\n",
      "Epoch 5/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7602 - loss: 0.8761 - val_accuracy: 0.7559 - val_loss: 0.9181\n",
      "Epoch 6/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7683 - loss: 0.8584 - val_accuracy: 0.7638 - val_loss: 0.8964\n",
      "Epoch 7/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7685 - loss: 0.8662 - val_accuracy: 0.7644 - val_loss: 0.8757\n",
      "Epoch 8/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7733 - loss: 0.8485 - val_accuracy: 0.7653 - val_loss: 0.8633\n",
      "Epoch 9/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7766 - loss: 0.8026 - val_accuracy: 0.7663 - val_loss: 0.8585\n",
      "Epoch 10/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7777 - loss: 0.7968 - val_accuracy: 0.7747 - val_loss: 0.8328\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[[1.3279967e-04 1.1702169e-03 1.8473719e-04 3.5824571e-04 9.7106688e-02\n",
      "  1.8075712e-04 1.3558395e-04 5.0365816e-05 1.3887356e-03 1.4273233e-03\n",
      "  8.9778804e-04 9.9711623e-03 7.5787465e-10 9.3363992e-09 4.8899489e-07\n",
      "  4.4130410e-08 6.1024763e-05 8.1322469e-05 4.8006926e-02 2.3189706e-03\n",
      "  2.8553282e-08 1.6574860e-09 1.2925738e-13 6.4754628e-02 1.0261386e-06\n",
      "  7.7177119e-01]\n",
      " [2.9610440e-02 2.6711256e-03 1.0417580e-02 1.6408959e-04 7.1177192e-02\n",
      "  1.6255198e-02 4.3144394e-03 5.2685761e-03 3.8987619e-03 1.2473478e-03\n",
      "  4.1686486e-02 1.3681374e-01 8.4135894e-07 1.5857143e-04 1.1101354e-04\n",
      "  1.0803562e-04 7.4480190e-03 1.8519594e-03 1.7929660e-02 2.2603504e-01\n",
      "  5.9232092e-04 1.6646116e-03 5.7320317e-06 3.6089492e-01 5.9167489e-02\n",
      "  5.0684973e-04]\n",
      " [9.9475020e-01 8.8815080e-09 2.5359822e-07 5.9018575e-08 2.1233850e-09\n",
      "  9.9691477e-10 3.4552602e-05 1.8790224e-05 4.6101981e-05 3.8296558e-04\n",
      "  1.9393347e-05 2.1644942e-03 1.0637546e-07 1.4096491e-07 1.2339852e-05\n",
      "  7.0265478e-09 2.3274415e-03 1.2133808e-06 3.1122872e-05 3.6184196e-09\n",
      "  1.1836449e-08 7.2278866e-10 6.9430833e-13 2.1075775e-04 1.3717261e-10\n",
      "  8.9461782e-10]\n",
      " [1.8205694e-05 1.3322647e-01 1.3607763e-02 1.1275845e-02 6.2236971e-01\n",
      "  2.8577270e-03 6.8430617e-02 2.4357568e-03 2.9128180e-03 8.3508370e-05\n",
      "  7.2524594e-03 4.7551543e-03 1.6152131e-07 8.3285627e-08 6.4787746e-04\n",
      "  4.1849718e-05 6.4965170e-03 1.7471783e-02 3.9730355e-02 1.2649357e-03\n",
      "  1.1473272e-06 1.1519780e-06 1.0414377e-09 5.4175984e-02 2.0638795e-06\n",
      "  1.0940128e-02]\n",
      " [5.2423878e-03 7.5152326e-05 1.5914500e-02 8.1895821e-04 4.3148763e-04\n",
      "  2.9295838e-05 1.5628147e-01 6.1589014e-03 2.9004840e-04 1.3852924e-03\n",
      "  1.8403010e-04 4.6760147e-03 2.1698816e-06 8.4819349e-06 6.2455315e-02\n",
      "  9.8801565e-06 7.2196561e-01 7.2617701e-04 5.4112342e-03 1.9235549e-03\n",
      "  6.6512328e-04 5.4721069e-05 3.4237249e-08 1.5212684e-02 6.8036556e-05\n",
      "  9.3345507e-06]]\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the training set\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Display first few predictions\n",
    "print(y_pred[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d0f84a-eadd-4337-971d-536b81db383c",
   "metadata": {},
   "source": [
    "●\tModify various hyperparameters, such as the number of hidden layers, neurons per hidden layer, activation functions, and learning rate, to observe their impact on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac9419c7-5daf-49f0-96d8-b0ae9e1a1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Function to build a model with adjustable parameters\n",
    "def create_model(num_hidden_layers=1, neurons_per_layer=64, activation='relu', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input layer (with the number of input features)\n",
    "    model.add(Dense(neurons_per_layer, activation=activation, input_shape=(X_train.shape[1],)))\n",
    "    \n",
    "    # Add hidden layers based on num_hidden_layers\n",
    "    for _ in range(num_hidden_layers - 1):\n",
    "        model.add(Dense(neurons_per_layer, activation=activation))\n",
    "        \n",
    "    # Output layer (number of classes with softmax for multi-class classification)\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "    \n",
    "    # Compile the model with adjustable learning rate\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0b5acd0-87f9-4b91-b338-5fda0fc1cd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.2237 - loss: 2.9093 - val_accuracy: 0.5381 - val_loss: 1.8106\n",
      "Epoch 2/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5831 - loss: 1.6387 - val_accuracy: 0.6619 - val_loss: 1.3421\n",
      "Epoch 3/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6723 - loss: 1.2507 - val_accuracy: 0.6950 - val_loss: 1.1734\n",
      "Epoch 4/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7011 - loss: 1.1049 - val_accuracy: 0.7209 - val_loss: 1.0790\n",
      "Epoch 5/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7269 - loss: 1.0214 - val_accuracy: 0.7291 - val_loss: 1.0311\n",
      "Epoch 6/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7478 - loss: 0.9456 - val_accuracy: 0.7559 - val_loss: 0.9666\n",
      "Epoch 7/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7671 - loss: 0.8987 - val_accuracy: 0.7509 - val_loss: 0.9428\n",
      "Epoch 8/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7573 - loss: 0.8680 - val_accuracy: 0.7644 - val_loss: 0.8872\n",
      "Epoch 9/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7675 - loss: 0.8398 - val_accuracy: 0.7769 - val_loss: 0.8519\n",
      "Epoch 10/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7808 - loss: 0.7954 - val_accuracy: 0.7803 - val_loss: 0.8254\n",
      "Test Loss: 0.783522367477417\n",
      "Test Accuracy: 0.7860000133514404\n"
     ]
    }
   ],
   "source": [
    "# Example: Train a model with different hyperparameters\n",
    "# Modify the values below to experiment with different configurations\n",
    "\n",
    "model = create_model(num_hidden_layers=2, neurons_per_layer=128, activation='tanh', learning_rate=0.0005)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5c0dcf-3eea-4ec4-ad9b-e02d0f79a14d",
   "metadata": {},
   "source": [
    "●\tAdopt a structured approach like grid search or random search for hyperparameter tuning, documenting your methodology thoroughly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ae8206a-e5a6-4568-bec6-7c951bf3a8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-tuner) (3.6.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-tuner) (23.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-tuner) (2.32.2)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\programdata\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\programdata\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (0.13.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\programdata\\anaconda3\\lib\\site-packages (from keras->keras-tuner) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2024.6.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from optree->keras->keras-tuner) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras->keras-tuner) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras->keras-tuner) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras->keras-tuner) (0.1.0)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "   ---------------------------------------- 0.0/129.1 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/129.1 kB ? eta -:--:--\n",
      "   --------------- ----------------------- 51.2/129.1 kB 660.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 122.9/129.1 kB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 122.9/129.1 kB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- 129.1/129.1 kB 585.7 kB/s eta 0:00:00\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "179f6279-eaea-40d7-9c2f-1d10216637c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define a hypermodel function for the Keras Tuner\n",
    "def build_hypermodel(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Define the input layer\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units_input', min_value=32, max_value=128, step=32),\n",
    "        activation=hp.Choice('activation_input', ['relu', 'tanh', 'sigmoid']),\n",
    "        input_shape=(X_train.shape[1],)\n",
    "    ))\n",
    "    \n",
    "    # Add hidden layers, iterating based on the selected number of layers\n",
    "    for i in range(hp.Int('num_hidden_layers', 1, 3)):\n",
    "        model.add(Dense(\n",
    "            units=hp.Int(f'units_{i}', min_value=32, max_value=128, step=32),\n",
    "            activation=hp.Choice(f'activation_{i}', ['relu', 'tanh', 'sigmoid'])\n",
    "        ))\n",
    "\n",
    "    # Define the output layer\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "    \n",
    "    # Compile the model with an adjustable learning rate\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Choice('learning_rate', [0.001, 0.0005, 0.0001])),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6305c037-6849-474e-967f-72d28ef67549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Keras Tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_hypermodel,\n",
    "    objective='val_accuracy',  # Optimize for validation accuracy\n",
    "    max_trials=5,              # Number of different hyperparameter combinations to try\n",
    "    executions_per_trial=1,     # Number of times to train each model\n",
    "    directory='hyperparameter_tuning',\n",
    "    project_name='ANN_tuning'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1df462fc-f68d-41d0-aa15-d94b902def15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 14s]\n",
      "val_accuracy: 0.46031248569488525\n",
      "\n",
      "Best val_accuracy So Far: 0.7975000143051147\n",
      "Total elapsed time: 00h 01m 06s\n",
      "Best Hyperparameters:\n",
      "Number of hidden layers: 2\n",
      "Units in each layer: [32, 32]\n",
      "Activation functions: ['tanh', 'relu']\n",
      "Learning rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "# Perform hyperparameter search\n",
    "tuner.search(X_train, y_train, epochs=10, validation_split=0.2, batch_size=32)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(f\"Number of hidden layers: {best_hps.get('num_hidden_layers')}\")\n",
    "print(f\"Units in each layer: {[best_hps.get(f'units_{i}') for i in range(best_hps.get('num_hidden_layers'))]}\")\n",
    "print(f\"Activation functions: {[best_hps.get(f'activation_{i}') for i in range(best_hps.get('num_hidden_layers'))]}\")\n",
    "print(f\"Learning rate: {best_hps.get('learning_rate')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "941cbe4a-0216-44cf-ac87-9870bb4ea8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1734 - loss: 2.9093 - val_accuracy: 0.5084 - val_loss: 1.7539\n",
      "Epoch 2/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5591 - loss: 1.5658 - val_accuracy: 0.6097 - val_loss: 1.3748\n",
      "Epoch 3/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6214 - loss: 1.2771 - val_accuracy: 0.6591 - val_loss: 1.2020\n",
      "Epoch 4/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6754 - loss: 1.1053 - val_accuracy: 0.7034 - val_loss: 1.0552\n",
      "Epoch 5/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7153 - loss: 0.9934 - val_accuracy: 0.7253 - val_loss: 0.9677\n",
      "Epoch 6/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7401 - loss: 0.9032 - val_accuracy: 0.7503 - val_loss: 0.8695\n",
      "Epoch 7/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7630 - loss: 0.8212 - val_accuracy: 0.7553 - val_loss: 0.8432\n",
      "Epoch 8/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7807 - loss: 0.7661 - val_accuracy: 0.7694 - val_loss: 0.7716\n",
      "Epoch 9/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7861 - loss: 0.7280 - val_accuracy: 0.7925 - val_loss: 0.7315\n",
      "Epoch 10/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7973 - loss: 0.6802 - val_accuracy: 0.7909 - val_loss: 0.7057\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8078 - loss: 0.6498\n",
      "Test Loss: 0.6659354567527771\n",
      "Test Accuracy: 0.7992500066757202\n"
     ]
    }
   ],
   "source": [
    "# Build the best model and train it on the training data\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "best_model.fit(X_train, y_train, epochs=10, validation_split=0.2, batch_size=32)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c6132f-4a6e-4782-9c94-48283505341a",
   "metadata": {},
   "source": [
    "●\tEmploy suitable metrics such as accuracy, precision, recall, and F1-score to evaluate your model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dd77fcb-a851-4f2a-ae6c-f1f98d056efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9576666666666667\n",
      "Precision: 0.9585732999536832\n",
      "Recall: 0.9576666666666667\n",
      "F1-Score: 0.9577311707476016\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      1.00      0.99       232\n",
      "           B       0.90      0.96      0.93       229\n",
      "           C       0.98      0.93      0.96       201\n",
      "           D       0.91      0.97      0.94       250\n",
      "           E       0.93      0.97      0.95       238\n",
      "           F       0.91      0.96      0.94       211\n",
      "           G       0.96      0.95      0.96       230\n",
      "           H       0.95      0.86      0.90       218\n",
      "           I       0.97      0.91      0.94       221\n",
      "           J       0.95      0.96      0.95       228\n",
      "           K       0.93      0.94      0.93       188\n",
      "           L       0.99      0.97      0.98       231\n",
      "           M       0.97      0.99      0.98       252\n",
      "           N       0.98      0.93      0.95       231\n",
      "           O       0.92      0.96      0.94       218\n",
      "           P       0.96      0.94      0.95       248\n",
      "           Q       0.96      0.95      0.96       253\n",
      "           R       0.89      0.96      0.92       234\n",
      "           S       0.97      0.97      0.97       235\n",
      "           T       0.97      0.97      0.97       232\n",
      "           U       1.00      0.96      0.98       261\n",
      "           V       0.98      0.96      0.97       237\n",
      "           W       0.99      0.99      0.99       213\n",
      "           X       0.98      0.98      0.98       245\n",
      "           Y       0.99      0.99      0.99       251\n",
      "           Z       0.99      0.96      0.97       213\n",
      "\n",
      "    accuracy                           0.96      6000\n",
      "   macro avg       0.96      0.96      0.96      6000\n",
      "weighted avg       0.96      0.96      0.96      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:/Users/DELL/OneDrive/Documents/data science asignments/Neural networks/Neural networks/Alphabets_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and target label\n",
    "X = data.drop('letter', axis=1)\n",
    "y = data['letter']\n",
    "\n",
    "# Encode the target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate using accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "classification_rep = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
    "\n",
    "# Display results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10500c9d-9dfb-4547-b8ba-f2e5fadd5d8c",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning Analysis\n",
    "Initial Model Performance (Default Hyperparameters)\n",
    "Validation Accuracy: The initial validation accuracy reached only about 46.03%.\n",
    "Hyperparameters: In the default configuration:\n",
    "Number of hidden layers: likely 1 layer with fewer units.\n",
    "Activation function: ReLU or another standard option.\n",
    "Learning rate: default (likely 0.01).\n",
    "The model initially had limited capacity, which restricted its ability to capture complex patterns, leading to low performance.\n",
    "Optimized Model Performance (Tuned Hyperparameters)\n",
    "Best Validation Accuracy: Achieved 79.75% after tuning.\n",
    "Test Accuracy: Reached 79.93%, showing significant improvement over the default.\n",
    "Best Hyperparameters:\n",
    "Number of Hidden Layers: Increased to 2 layers, allowing for more complex feature representations.\n",
    "Units in Each Layer: Configured with 32 units per layer to balance model complexity and training time.\n",
    "Activation Functions: A mix of Tanh (for the first layer) and ReLU (for the second layer), combining the benefits of smoother gradients and faster convergence.\n",
    "Learning Rate: Tuned down to 0.001, enabling a more stable learning process, which helped avoid overshooting optimal points during training.\n",
    "Performance Impact of Hyperparameter Tuning\n",
    "Model Complexity: Adding a second hidden layer and increasing the units per layer allowed the model to capture more intricate patterns in the data, directly contributing to the improved accuracy.\n",
    "Activation Functions: The mix of Tanh and ReLU offered a balance between non-linearity (Tanh) and efficient gradient propagation (ReLU).\n",
    "Learning Rate Adjustment: A lower learning rate of 0.001 stabilized the training, enhancing the model's ability to converge on a better solution.\n",
    "Conclusion\n",
    "Hyperparameter tuning significantly improved the model’s ability to generalize, as shown by the increase in validation accuracy from 46% to nearly 80%. This improvement underscores the importance of tuning key aspects such as layer architecture, activation functions, and learning rate for achieving optimal performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
